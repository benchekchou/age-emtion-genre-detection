

````markdown
# ğŸ­ Age, Gender & Emotion Detection

## ğŸ“Œ Description
Ce projet propose un modÃ¨le intelligent de reconnaissance faciale en temps rÃ©el, capable de dÃ©tecter **lâ€™Ã¢ge, le genre et lâ€™Ã©motion** dâ€™une personne Ã  partir dâ€™une image ou dâ€™une vidÃ©o.  
Il combine **MTCNN** pour la dÃ©tection de visages et des **CNNs spÃ©cialisÃ©s** pour la classification des attributs (Ã¢ge, genre et Ã©motions).  

ğŸ“„ Le projet est dÃ©taillÃ© dans lâ€™article scientifique suivant :  
ğŸ‘‰ [Toward Affective Intelligence: Real-Time Age, Gender, and Emotion Detection via Multi-CNN and MTCNN Integration](./output_47.pdf)

---

## ğŸš€ FonctionnalitÃ©s
- DÃ©tection en temps rÃ©el des visages.
- Classification de lâ€™Ã¢ge, du genre et de lâ€™Ã©motion.
- Interface simple pour tester avec des images.
- RÃ©sultats robustes mÃªme sous des conditions difficiles (Ã©clairage faible, angles variÃ©s, occlusions partielles).

---

## ğŸ§  ModÃ¨les & Jeux de DonnÃ©es
- **MTCNN** : dÃ©tection et alignement des visages.
- **CNN spÃ©cialisÃ©s** :
- **Ã‚ge** : UTKFace, Combined_Faces
- **Genre** : UTKFace
 - **Ã‰motions** : CK+48 (7 Ã©motions : joie, tristesse, colÃ¨re, dÃ©goÃ»t, surprise, peur, neutralitÃ©)

**Performances obtenues :**
- Ã‚ge : 89% de prÃ©cision
- Genre : 88% de prÃ©cision
- Ã‰motions : 99% de prÃ©cision
- Moyenne globale : ~92%

---

## ğŸ“Š Architecture
```mermaid
flowchart TD
    A[Image/VidÃ©o] --> B[MTCNN - DÃ©tection du visage]
    B --> C[PrÃ©traitement (resize, normalisation...)]
    C --> D1[Ã‚ge - CNN]
    C --> D2[Genre - CNN]
    C --> D3[Ã‰motions - CNN]
    D1 --> E[Fusion & RÃ©sultats]
    D2 --> E
    D3 --> E
    E --> F[Affichage : Ã¢ge, genre, Ã©motion]
````

---

## âš™ï¸ Installation

```bash
# Cloner le projet
git clone https://github.com/benchekchou/age-emtion-genre-detection.git
cd age-emtion-genre-detection

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate   # sous Linux/Mac
venv\Scripts\activate      # sous Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

---


---

## ğŸ“‚ Structure du Projet

```
age-emtion-genre-detection/
â”‚â”€â”€ models/           # ModÃ¨les CNN prÃ©-entraÃ®nÃ©s
â”‚â”€â”€ datasets/         # Jeux de donnÃ©es (si disponibles localement)
â”‚â”€â”€ detect.py         # Script principal de dÃ©tection
â”‚â”€â”€ utils/            # Fonctions utilitaires (prÃ©traitement, affichage...)
â”‚â”€â”€ requirements.txt  # DÃ©pendances
â”‚â”€â”€ output_47.pdf     # Article scientifique du projet
â”‚â”€â”€ README.md         # Ce fichier
```

---

## ğŸ‘¥ Auteurs

* Hamza Benchekchou â€“ [GitHub](https://github.com/benchekchou)
* Halima Rissouni

---

## ğŸ“œ Licence

Ce projet est publiÃ© sous licence **MIT** â€“ libre pour utilisation, modification et distribution.

---

âœ¨ Nâ€™hÃ©sitez pas Ã  forker le projet, proposer des amÃ©liorations ou lâ€™utiliser dans vos propres applications liÃ©es Ã  lâ€™IA et Ã  la reconnaissance faciale !

```

---

Veux-tu que je prÃ©pare aussi un **badge Shields.io** (par ex. Python, TensorFlow, Licence MIT) et un **aperÃ§u visuel (screenshot ou GIF de dÃ©mo)** dans le README pour le rendre plus attractif ?
```
